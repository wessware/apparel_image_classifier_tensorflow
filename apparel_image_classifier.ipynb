{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NEfAO7xgeKrs"
      },
      "outputs": [],
      "source": [
        "from platform import python_version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-_NKcJikW1q",
        "outputId": "81f4701b-038b-4575-e3e8-086efd2cd518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.13\n"
          ]
        }
      ],
      "source": [
        "print(python_version())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t74gNCS_lAJW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from skimage.io import imread_collection\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zuo406RJlY2O"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(\"/content/sample_data/male/male.zip\", \"r\") as zip_ref:\n",
        "  zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "595U-1YmpYQD",
        "outputId": "6e8117ee-5f65-4787-c285-2289af200a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getcwd   :  /content\n"
          ]
        }
      ],
      "source": [
        "print('getcwd   : ', os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUVJNi7G0JW0",
        "outputId": "a9e43fa7-a889-4241-92b7-1261ff1764c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of men shoes pictures: 757.\n"
          ]
        }
      ],
      "source": [
        "#reading folder\n",
        "men = \"/content/*.jpg\"\n",
        "#create image collection\n",
        "men_shoes = imread_collection(men)\n",
        "print(f\"Number of men shoes pictures: {len(men_shoes)}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qmi-pyq80wuC"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(\"/content/sample_data/female/female.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRcgdKOJ1IwT",
        "outputId": "16a0afcd-c895-4360-82c2-02018bafca4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of women shoes pictures: 757.\n"
          ]
        }
      ],
      "source": [
        "#reading folder\n",
        "women = \"/content/*.jpg\"\n",
        "#create image collection\n",
        "women_shoes = imread_collection(women)\n",
        "print(f\"Number of women shoes pictures: {len(women_shoes)}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YZ_rBJz91_Y5"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import applications"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras import backend as k\n",
        "#from tensorflow.keras import Conv2D, Dense, Flatten\n",
        "import keras"
      ],
      "metadata": {
        "id": "qOkXZVZM-YMj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mdl = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAN0fXWC_aed",
        "outputId": "b7a3918d-9b32-4f5a-b951-532f9859a4e5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_mdl.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG5n7xC1AuDA",
        "outputId": "af5d09a2-04a8-43f2-807b-574eed0c1f97"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(data): \n",
        "  image = load_img(data, target_size=(224, 224))\n",
        "  image = img_to_array(image)\n",
        "\n",
        "  image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
        "\n",
        "  image = preprocess_input(image)\n",
        "\n",
        "  features = model_mdl.predict(image)\n",
        "\n",
        "  return features"
      ],
      "metadata": {
        "id": "tP__UgrSA18E"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R3OCvq_2C3Ja"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "apparel_image_classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNR5mHTcjWqYp6LqWOQjiMS"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}